# -*- coding: utf-8 -*-
"""KFOLD TAGUCHI.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ZhCF7LMurrl7HtstOT4rQGLE--ZR9y_F
"""

import numpy as np
import os
import shutil
from sklearn.model_selection import KFold
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Input, Conv2D, DepthwiseConv2D, MaxPooling2D, AveragePooling2D, Concatenate, GlobalAveragePooling2D, Dense, Dropout
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau
from tensorflow.keras.utils import to_categorical
from tensorflow.keras.optimizers import Adam
import numpy as np
import tensorflow as tf
from tensorflow.keras.layers import (
    Input, Conv2D, BatchNormalization, MaxPooling2D, UpSampling2D, Dense,
    Concatenate, GlobalAveragePooling2D, Layer
)
from tensorflow.keras.models import Model


# Helper function to load image paths and labels
def load_image_paths_and_labels(data_dir):
    image_paths = []
    labels = []
    class_names = os.listdir(data_dir)
    for class_index, class_name in enumerate(class_names):
        class_dir = os.path.join(data_dir, class_name)
        if os.path.isdir(class_dir):
            for image_name in os.listdir(class_dir):
                image_paths.append(os.path.join(class_dir, image_name))
                labels.append(class_index)
    return np.array(image_paths), np.array(labels)



# Setup K-fold cross-validation
n_splits = 5
kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)

# Define a subclassed Layer for fuzzification
class FuzzifyLayer(Layer):
    def __init__(self, a=0.2, b=0.5, c=0.8, **kwargs):
        super(FuzzifyLayer, self).__init__(**kwargs)
        self.a = a
        self.b = b
        self.c = c

    def call(self, inputs):
        return tf.maximum(
            0.0,
            tf.minimum((inputs - self.a) / (self.b - self.a), (self.c - inputs) / (self.c - self.b))
        )

# Input layer
input_layer = Input(shape=(224, 224, 3))

# -----------------------------
# Denoising Expert
# -----------------------------
denoising_x = Conv2D(16, (3, 3), activation='relu', padding='same')(input_layer)
denoising_x = BatchNormalization()(denoising_x)
denoising_x = MaxPooling2D((2, 2), padding='same')(denoising_x)

denoising_x = Conv2D(32, (3, 3), activation='relu', padding='same')(denoising_x)
denoising_x = BatchNormalization()(denoising_x)
denoising_x = MaxPooling2D((2, 2), padding='same')(denoising_x)

denoising_x = Conv2D(32, (3, 3), activation='relu', padding='same')(denoising_x)
denoising_x = UpSampling2D((2, 2))(denoising_x)

denoising_x = Conv2D(16, (3, 3), activation='relu', padding='same')(denoising_x)
denoising_x = UpSampling2D((2, 2))(denoising_x)

denoising_x = Conv2D(32, (3, 3), activation='relu', padding='same')(denoising_x)
denoised_features = GlobalAveragePooling2D()(denoising_x)

# -----------------------------
# Fuzzy Logic Expert
# -----------------------------
fuzzy_input = FuzzifyLayer()(input_layer)

fuzzy_x = Conv2D(32, (5, 5), activation='relu', padding='same')(fuzzy_input)
fuzzy_x = BatchNormalization()(fuzzy_x)
fuzzy_x = Conv2D(64, (5, 5), activation='relu', padding='same')(fuzzy_x)
fuzzy_x = MaxPooling2D((2, 2))(fuzzy_x)

fuzzy_x = Conv2D(128, (3, 3), activation='relu', padding='same')(fuzzy_x)
fuzzy_features = GlobalAveragePooling2D()(fuzzy_x)

# -----------------------------
# Adversarially Trained Expert
# -----------------------------
adversarial_x = Conv2D(64, (3, 3), activation='relu', padding='same')(input_layer)
adversarial_x = BatchNormalization()(adversarial_x)
adversarial_x = Conv2D(128, (3, 3), activation='relu', padding='same')(adversarial_x)
adversarial_x = MaxPooling2D((2, 2))(adversarial_x)

adversarial_x = Conv2D(256, (3, 3), activation='relu', padding='same')(adversarial_x)
adversarial_features = GlobalAveragePooling2D()(adversarial_x)

# -----------------------------
# Combine Features and Gating Network
# -----------------------------
combined_features = Concatenate()([fuzzy_features, adversarial_features, denoised_features])

gating_x = Dense(512, activation='relu')(combined_features)
final_output = Dense(4, activation='softmax')(gating_x)

# -----------------------------
# Build and Compile Model
# -----------------------------
model = Model(inputs=input_layer, outputs=final_output)

# Model Summary
model.summary()


# Load image paths and labels
data_dir = '/content/drive/MyDrive/Colab Notebooks/BT/Training'
image_paths, labels = load_image_paths_and_labels(data_dir)

# Check if there are enough samples for the number of splits
if len(image_paths) < n_splits:
    raise ValueError(f"Number of splits n_splits={n_splits} is greater than the number of samples: n_samples={len(image_paths)}.")

# Convert labels to categorical
labels = to_categorical(labels)

# Image data generator for rescaling images
datagen = ImageDataGenerator(rescale=1./255)

# Temporary directory for cross-validation splits
temp_dir = '/content/temp_kfold'
if not os.path.exists(temp_dir):
    os.makedirs(temp_dir)

from sklearn.metrics import classification_report, confusion_matrix, cohen_kappa_score
import matplotlib.pyplot as plt
import seaborn as sns

# Initialize lists to store metrics
acc_per_fold = []
loss_per_fold = []
kappa_per_fold = []
classification_reports = []  # To store classification reports for each fold
confusion_matrices = []      # To store confusion matrices for each fold

fold_no = 1
for train_index, val_index in kf.split(image_paths):
    print(f'Training for fold {fold_no} ...')

    # Split data into training and validation sets
    train_paths, val_paths = image_paths[train_index], image_paths[val_index]
    train_labels, val_labels = labels[train_index], labels[val_index]

    # Create subdirectories for training and validation data
    train_dir = os.path.join(temp_dir, 'train')
    val_dir = os.path.join(temp_dir, 'val')

    # Clean up previous fold directories
    if os.path.exists(train_dir):
        shutil.rmtree(train_dir)
    if os.path.exists(val_dir):
        shutil.rmtree(val_dir)

    os.makedirs(train_dir)
    os.makedirs(val_dir)

    # Copy training data to temporary directory
    for path, label in zip(train_paths, train_labels):
        class_dir = os.path.join(train_dir, str(np.argmax(label)))
        if not os.path.exists(class_dir):
            os.makedirs(class_dir)
        shutil.copy(path, os.path.join(class_dir, os.path.basename(path)))

    # Copy validation data to temporary directory
    for path, label in zip(val_paths, val_labels):
        class_dir = os.path.join(val_dir, str(np.argmax(label)))
        if not os.path.exists(class_dir):
            os.makedirs(class_dir)
        shutil.copy(path, os.path.join(class_dir, os.path.basename(path)))

    # Create data generators
    train_gen = datagen.flow_from_directory(train_dir, target_size=(224, 224), batch_size=32, shuffle=True, class_mode="categorical")
    val_gen = datagen.flow_from_directory(val_dir, target_size=(224, 224), batch_size=16, shuffle=False, class_mode="categorical")

    opt = tf.keras.optimizers.Adam(learning_rate=0.001)
    model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])

    # Train the model
    history = model.fit(train_gen, epochs=50, validation_data=val_gen, verbose=1)

    # Evaluate the model
    scores = model.evaluate(val_gen, verbose=0)
    print(f'Score for fold {fold_no}: {model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]}%')

    # Store metrics for this fold
    acc_per_fold.append(scores[1] * 100)
    loss_per_fold.append(scores[0])

    # Get predictions and true labels
    val_predictions = model.predict(val_gen)
    y_pred = np.argmax(val_predictions, axis=1)
    y_true = val_gen.classes

    # Cohen's Kappa Score
    kappa = cohen_kappa_score(y_true, y_pred)
    kappa_per_fold.append(kappa)
    print(f'Cohen\'s Kappa Score for fold {fold_no}: {kappa}')

    # Classification report
    report = classification_report(y_true, y_pred, target_names=val_gen.class_indices.keys())
    print(f"Classification Report for fold {fold_no}:\n{report}")
    classification_reports.append(report)

    # Confusion matrix
    cm = confusion_matrix(y_true, y_pred)
    confusion_matrices.append(cm)

    # Plot confusion matrix
    plt.figure(figsize=(8, 6))
    sns.heatmap(cm, annot=True, fmt="d", cmap="Blues", xticklabels=val_gen.class_indices.keys(), yticklabels=val_gen.class_indices.keys())
    plt.title(f"Confusion Matrix for Fold {fold_no}")
    plt.xlabel("Predicted")
    plt.ylabel("Actual")
    plt.show()

    fold_no += 1

# Print the summary of each fold
print('------------------------------------------------------------------------')
print('Score per fold')
for i in range(0, len(acc_per_fold)):
    print('------------------------------------------------------------------------')
    print(f'> Fold {i+1} - Loss: {loss_per_fold[i]} - Accuracy: {acc_per_fold[i]}% - Kappa: {kappa_per_fold[i]}')
print('------------------------------------------------------------------------')
print('Average scores for all folds:')
print(f'> Accuracy: {np.mean(acc_per_fold)} (+- {np.std(acc_per_fold)})')
print(f'> Loss: {np.mean(loss_per_fold)}')
print(f'> Cohen\'s Kappa: {np.mean(kappa_per_fold)} (+- {np.std(kappa_per_fold)})')
print('------------------------------------------------------------------------')







import numpy as np
import os
import shutil
from sklearn.model_selection import KFold
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Input, Conv2D, DepthwiseConv2D, MaxPooling2D, AveragePooling2D, Concatenate, GlobalAveragePooling2D, Dense, Dropout
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau
from tensorflow.keras.utils import to_categorical
from tensorflow.keras.optimizers import Adam
import numpy as np
import tensorflow as tf
from tensorflow.keras.layers import (
    Input, Conv2D, BatchNormalization, MaxPooling2D, UpSampling2D, Dense,
    Concatenate, GlobalAveragePooling2D, Layer
)
from tensorflow.keras.models import Model


# Helper function to load image paths and labels
def load_image_paths_and_labels(data_dir):
    image_paths = []
    labels = []
    class_names = os.listdir(data_dir)
    for class_index, class_name in enumerate(class_names):
        class_dir = os.path.join(data_dir, class_name)
        if os.path.isdir(class_dir):
            for image_name in os.listdir(class_dir):
                image_paths.append(os.path.join(class_dir, image_name))
                labels.append(class_index)
    return np.array(image_paths), np.array(labels)



# Setup K-fold cross-validation
n_splits = 5
kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)

# Define a subclassed Layer for fuzzification
class FuzzifyLayer(Layer):
    def __init__(self, a=0.2, b=0.5, c=0.8, **kwargs):
        super(FuzzifyLayer, self).__init__(**kwargs)
        self.a = a
        self.b = b
        self.c = c

    def call(self, inputs):
        return tf.maximum(
            0.0,
            tf.minimum((inputs - self.a) / (self.b - self.a), (self.c - inputs) / (self.c - self.b))
        )

# Input layer
input_layer = Input(shape=(224, 224, 3))

# -----------------------------
# Denoising Expert
# -----------------------------
denoising_x = Conv2D(16, (3, 3), activation='relu', padding='same')(input_layer)
denoising_x = BatchNormalization()(denoising_x)
denoising_x = MaxPooling2D((2, 2), padding='same')(denoising_x)

denoising_x = Conv2D(32, (3, 3), activation='relu', padding='same')(denoising_x)
denoising_x = BatchNormalization()(denoising_x)
denoising_x = MaxPooling2D((2, 2), padding='same')(denoising_x)

denoising_x = Conv2D(32, (3, 3), activation='relu', padding='same')(denoising_x)
denoising_x = UpSampling2D((2, 2))(denoising_x)

denoising_x = Conv2D(16, (3, 3), activation='relu', padding='same')(denoising_x)
denoising_x = UpSampling2D((2, 2))(denoising_x)

denoising_x = Conv2D(32, (3, 3), activation='relu', padding='same')(denoising_x)
denoised_features = GlobalAveragePooling2D()(denoising_x)

# -----------------------------
# Fuzzy Logic Expert
# -----------------------------
fuzzy_input = FuzzifyLayer()(input_layer)

fuzzy_x = Conv2D(32, (5, 5), activation='relu', padding='same')(fuzzy_input)
fuzzy_x = BatchNormalization()(fuzzy_x)
fuzzy_x = Conv2D(64, (5, 5), activation='relu', padding='same')(fuzzy_x)
fuzzy_x = MaxPooling2D((2, 2))(fuzzy_x)

fuzzy_x = Conv2D(128, (3, 3), activation='relu', padding='same')(fuzzy_x)
fuzzy_features = GlobalAveragePooling2D()(fuzzy_x)

# -----------------------------
# Adversarially Trained Expert
# -----------------------------
adversarial_x = Conv2D(64, (3, 3), activation='relu', padding='same')(input_layer)
adversarial_x = BatchNormalization()(adversarial_x)
adversarial_x = Conv2D(128, (3, 3), activation='relu', padding='same')(adversarial_x)
adversarial_x = MaxPooling2D((2, 2))(adversarial_x)

adversarial_x = Conv2D(256, (3, 3), activation='relu', padding='same')(adversarial_x)
adversarial_features = GlobalAveragePooling2D()(adversarial_x)

# -----------------------------
# Combine Features and Gating Network
# -----------------------------
combined_features = Concatenate()([fuzzy_features, adversarial_features, denoised_features])

gating_x = Dense(512, activation='relu')(combined_features)
final_output = Dense(3, activation='softmax')(gating_x)

# -----------------------------
# Build and Compile Model
# -----------------------------
model = Model(inputs=input_layer, outputs=final_output)

# Model Summary
model.summary()


# Load image paths and labels
data_dir = '/content/drive/MyDrive/Colab Notebooks/BT/Training'
image_paths, labels = load_image_paths_and_labels(data_dir)

# Check if there are enough samples for the number of splits
if len(image_paths) < n_splits:
    raise ValueError(f"Number of splits n_splits={n_splits} is greater than the number of samples: n_samples={len(image_paths)}.")

# Convert labels to categorical
labels = to_categorical(labels)

# Image data generator for rescaling images
datagen = ImageDataGenerator(rescale=1./255)

# Temporary directory for cross-validation splits
temp_dir = '/content/temp_kfold'
if not os.path.exists(temp_dir):
    os.makedirs(temp_dir)

from sklearn.metrics import classification_report, confusion_matrix, cohen_kappa_score
import matplotlib.pyplot as plt
import seaborn as sns

# Initialize lists to store metrics
acc_per_fold = []
loss_per_fold = []
kappa_per_fold = []
classification_reports = []  # To store classification reports for each fold
confusion_matrices = []      # To store confusion matrices for each fold

fold_no = 1
for train_index, val_index in kf.split(image_paths):
    print(f'Training for fold {fold_no} ...')

    # Split data into training and validation sets
    train_paths, val_paths = image_paths[train_index], image_paths[val_index]
    train_labels, val_labels = labels[train_index], labels[val_index]

    # Create subdirectories for training and validation data
    train_dir = os.path.join(temp_dir, 'train')
    val_dir = os.path.join(temp_dir, 'val')

    # Clean up previous fold directories
    if os.path.exists(train_dir):
        shutil.rmtree(train_dir)
    if os.path.exists(val_dir):
        shutil.rmtree(val_dir)

    os.makedirs(train_dir)
    os.makedirs(val_dir)

    # Copy training data to temporary directory
    for path, label in zip(train_paths, train_labels):
        class_dir = os.path.join(train_dir, str(np.argmax(label)))
        if not os.path.exists(class_dir):
            os.makedirs(class_dir)
        shutil.copy(path, os.path.join(class_dir, os.path.basename(path)))

    # Copy validation data to temporary directory
    for path, label in zip(val_paths, val_labels):
        class_dir = os.path.join(val_dir, str(np.argmax(label)))
        if not os.path.exists(class_dir):
            os.makedirs(class_dir)
        shutil.copy(path, os.path.join(class_dir, os.path.basename(path)))

    # Create data generators
    train_gen = datagen.flow_from_directory(train_dir, target_size=(224, 224), batch_size=32, shuffle=True, class_mode="categorical")
    val_gen = datagen.flow_from_directory(val_dir, target_size=(224, 224), batch_size=16, shuffle=False, class_mode="categorical")

    opt = tf.keras.optimizers.Adam(learning_rate=0.001)
    model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])

    # Train the model
    history = model.fit(train_gen, epochs=50, validation_data=val_gen, verbose=1)

    # Evaluate the model
    scores = model.evaluate(val_gen, verbose=0)
    print(f'Score for fold {fold_no}: {model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]}%')

    # Store metrics for this fold
    acc_per_fold.append(scores[1] * 100)
    loss_per_fold.append(scores[0])

    # Get predictions and true labels
    val_predictions = model.predict(val_gen)
    y_pred = np.argmax(val_predictions, axis=1)
    y_true = val_gen.classes

    # Cohen's Kappa Score
    kappa = cohen_kappa_score(y_true, y_pred)
    kappa_per_fold.append(kappa)
    print(f'Cohen\'s Kappa Score for fold {fold_no}: {kappa}')

    # Classification report
    report = classification_report(y_true, y_pred, target_names=val_gen.class_indices.keys())
    print(f"Classification Report for fold {fold_no}:\n{report}")
    classification_reports.append(report)

    # Confusion matrix
    cm = confusion_matrix(y_true, y_pred)
    confusion_matrices.append(cm)

    # Plot confusion matrix
    plt.figure(figsize=(8, 6))
    sns.heatmap(cm, annot=True, fmt="d", cmap="Blues", xticklabels=val_gen.class_indices.keys(), yticklabels=val_gen.class_indices.keys())
    plt.title(f"Confusion Matrix for Fold {fold_no}")
    plt.xlabel("Predicted")
    plt.ylabel("Actual")
    plt.show()

    fold_no += 1

# Print the summary of each fold
print('------------------------------------------------------------------------')
print('Score per fold')
for i in range(0, len(acc_per_fold)):
    print('------------------------------------------------------------------------')
    print(f'> Fold {i+1} - Loss: {loss_per_fold[i]} - Accuracy: {acc_per_fold[i]}% - Kappa: {kappa_per_fold[i]}')
print('------------------------------------------------------------------------')
print('Average scores for all folds:')
print(f'> Accuracy: {np.mean(acc_per_fold)} (+- {np.std(acc_per_fold)})')
print(f'> Loss: {np.mean(loss_per_fold)}')
print(f'> Cohen\'s Kappa: {np.mean(kappa_per_fold)} (+- {np.std(kappa_per_fold)})')
print('------------------------------------------------------------------------')











!pip install gradio

pip install --upgrade gradio

import gradio as gr
import numpy as np
import cv2
from tensorflow.keras.models import load_model
from tensorflow.keras.preprocessing.image import ImageDataGenerator

# ---------------------------
# Load Pretrained Model
# ---------------------------
model_path = '/content/drive/MyDrive/Colab Notebooks/mebf/sn1.keras'
model = load_model(model_path)

# ---------------------------
# Dataset Configuration
# ---------------------------
datagen = ImageDataGenerator(rescale=1./255)

training_set = datagen.flow_from_directory(
    '/content/drive/MyDrive/Colab Notebooks/BT/Training',
    target_size=(128, 128),
    batch_size=32,
    shuffle=True,
    class_mode='categorical'
)

val_set = datagen.flow_from_directory(
    '/content/drive/MyDrive/Colab Notebooks/BT/Testing',
    target_size=(128, 128),
    batch_size=16,
    shuffle=False,
    class_mode="categorical"
)

test_set = datagen.flow_from_directory(
    '/content/drive/MyDrive/Colab Notebooks/BT/Testing',
    target_size=(128, 128),
    batch_size=32,
    shuffle=False,
    class_mode="categorical"
)

class_labels = list(test_set.class_indices.keys())

# ---------------------------
# Helper Functions
# ---------------------------
def preprocess_image(image, target_size=(128, 128)):
    if len(image.shape) == 2:  # Grayscale
        image = cv2.cvtColor(image, cv2.COLOR_GRAY2RGB)
    elif image.shape[-1] != 3:
        raise ValueError("Input image must have 3 channels (RGB).")
    image_resized = cv2.resize(image, target_size)
    image_normalized = image_resized / 255.0
    return np.expand_dims(image_normalized, axis=0)

def predict(image, ground_truth=None):
    try:
        preprocessed_image = preprocess_image(image)
        predictions = model.predict(preprocessed_image)
        results = {class_labels[i]: float(predictions[0][i]) for i in range(len(class_labels))}
        predicted_class = max(results, key=results.get)
        confidence = results[predicted_class]

        if ground_truth:
            if predicted_class != ground_truth:
                return (
                    f"Misclassified: Predicted '{predicted_class}' instead of '{ground_truth}' "
                    f"(Confidence: {confidence*100:.2f}%)",
                    results,
                )
        return f"Predicted Class: {predicted_class} (Confidence: {confidence*100:.2f}%)", results
    except Exception as e:
        return f"Prediction Error: {str(e)}", {}

# ---------------------------
# Gradio Interface
# ---------------------------
interface = gr.Interface(
    fn=predict,
    inputs=[
        gr.Image(type="numpy", label="Upload Chest X-Ray Image"),
        gr.Textbox(lines=1, placeholder="Enter Ground Truth Label (optional)", label="Ground Truth"),
    ],
    outputs=[
        gr.Textbox(label="Prediction"),
        gr.Label(label="Class Probabilities"),
    ],
    title="Brain MRI clasifiction",
    description=(
        "This tool uses a trained CNN model to classify chest X-ray images into categories. "
        "Upload an image and optionally provide a ground truth label to detect misclassifications."
    ),

)
if __name__ == "__main__":
    interface.launch()



from tensorflow.keras.models import load_model

# Load the model from the .h5 file
model = load_model('/content/drive/MyDrive/Colab Notebooks/copy3 class 3264MNET.keras')



pip install psutil

import time
import os
import psutil

import numpy as np
import os
import shutil
import subprocess
import psutil
from sklearn.model_selection import KFold
import tensorflow as tf
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Input, Conv2D, BatchNormalization, MaxPooling2D, UpSampling2D, Dense, Concatenate, GlobalAveragePooling2D, Layer
from tensorflow.keras.utils import to_categorical, Sequence
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.preprocessing.image import load_img, img_to_array
import matplotlib.pyplot as plt

# Helper function to load image paths and labels
def load_image_paths_and_labels(data_dir):
    image_paths = []
    labels = []
    class_names = sorted(os.listdir(data_dir))
    for class_index, class_name in enumerate(class_names):
        class_dir = os.path.join(data_dir, class_name)
        if os.path.isdir(class_dir):
            for image_name in os.listdir(class_dir):
                image_paths.append(os.path.join(class_dir, image_name))
                labels.append(class_index)
    return np.array(image_paths), np.array(labels), class_names

# Function to get GPU utilization using nvidia-smi
def get_gpu_utilization():
    try:
        result = subprocess.check_output(['nvidia-smi', '--query-gpu=utilization.gpu', '--format=csv,noheader,nounits'])
        return float(result.decode('utf-8').strip())
    except Exception as e:
        print(f"Error fetching GPU utilization: {e}")
        return 0.0

# Custom generator for loading images
class CustomImageSequence(Sequence):
    def __init__(self, image_paths, labels, batch_size, target_size):
        self.image_paths = image_paths
        self.labels = labels
        self.batch_size = batch_size
        self.target_size = target_size

    def __len__(self):
        return int(np.ceil(len(self.image_paths) / self.batch_size))

    def __getitem__(self, idx):
        batch_paths = self.image_paths[idx * self.batch_size:(idx + 1) * self.batch_size]
        batch_labels = self.labels[idx * self.batch_size:(idx + 1) * self.batch_size]

        images = []
        for path in batch_paths:
            img = load_img(path, target_size=self.target_size)
            img = img_to_array(img) / 255.0  # Normalize images to [0, 1]
            images.append(img)

        return np.array(images), np.array(batch_labels)

# Define a subclassed Layer for fuzzification
class FuzzifyLayer(Layer):
    def __init__(self, a=0.2, b=0.5, c=0.8, **kwargs):
        super(FuzzifyLayer, self).__init__(**kwargs)
        self.a = a
        self.b = b
        self.c = c

    def call(self, inputs):
        return tf.maximum(
            0.0,
            tf.minimum((inputs - self.a) / (self.b - self.a), (self.c - inputs) / (self.c - self.b))
        )

# Input layer
input_layer = Input(shape=(224, 224, 3))

# Denoising Expert
denoising_x = Conv2D(16, (3, 3), activation='relu', padding='same')(input_layer)
denoising_x = BatchNormalization()(denoising_x)
denoising_x = MaxPooling2D((2, 2), padding='same')(denoising_x)

denoising_x = Conv2D(32, (3, 3), activation='relu', padding='same')(denoising_x)
denoising_x = BatchNormalization()(denoising_x)
denoising_x = MaxPooling2D((2, 2), padding='same')(denoising_x)

denoising_x = Conv2D(32, (3, 3), activation='relu', padding='same')(denoising_x)
denoising_x = UpSampling2D((2, 2))(denoising_x)

denoising_x = Conv2D(16, (3, 3), activation='relu', padding='same')(denoising_x)
denoising_x = UpSampling2D((2, 2))(denoising_x)

denoising_x = Conv2D(32, (3, 3), activation='relu', padding='same')(denoising_x)
denoised_features = GlobalAveragePooling2D()(denoising_x)

# Fuzzy Logic Expert
fuzzy_input = FuzzifyLayer()(input_layer)

fuzzy_x = Conv2D(32, (5, 5), activation='relu', padding='same')(fuzzy_input)
fuzzy_x = BatchNormalization()(fuzzy_x)
fuzzy_x = Conv2D(64, (5, 5), activation='relu', padding='same')(fuzzy_x)
fuzzy_x = MaxPooling2D((2, 2))(fuzzy_x)

fuzzy_x = Conv2D(128, (3, 3), activation='relu', padding='same')(fuzzy_x)
fuzzy_features = GlobalAveragePooling2D()(fuzzy_x)

# Adversarially Trained Expert
adversarial_x = Conv2D(64, (3, 3), activation='relu', padding='same')(input_layer)
adversarial_x = BatchNormalization()(adversarial_x)
adversarial_x = Conv2D(128, (3, 3), activation='relu', padding='same')(adversarial_x)
adversarial_x = MaxPooling2D((2, 2))(adversarial_x)

adversarial_x = Conv2D(256, (3, 3), activation='relu', padding='same')(adversarial_x)
adversarial_features = GlobalAveragePooling2D()(adversarial_x)

# Combine Features and Gating Network
combined_features = Concatenate()([fuzzy_features, adversarial_features, denoised_features])

gating_x = Dense(512, activation='relu')(combined_features)
final_output = Dense(3, activation='softmax')(gating_x)

# Build and Compile Model
model = Model(inputs=input_layer, outputs=final_output)
model.summary()
model.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])

# Load data
data_dir = '/content/drive/MyDrive/Colab Notebooks/BT/Training'
image_paths, labels, class_names = load_image_paths_and_labels(data_dir)
labels = to_categorical(labels, num_classes=len(class_names))

# K-Fold Cross-Validation
n_splits = 5
kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)

foldwise_gpu_cpu_utilization = {}
fold_no = 1

for train_index, val_index in kf.split(image_paths):
    print(f"Training for fold {fold_no} ...")
    train_paths, val_paths = image_paths[train_index], image_paths[val_index]
    train_labels, val_labels = labels[train_index], labels[val_index]

    train_gen = CustomImageSequence(train_paths, train_labels, batch_size=32, target_size=(224, 224))
    val_gen = CustomImageSequence(val_paths, val_labels, batch_size=32, target_size=(224, 224))

    gpu_utilization_fold = []
    cpu_utilization_fold = []

    history = model.fit(
        train_gen,
        epochs=50,
        validation_data=val_gen,
        verbose=1,
        callbacks=[
            tf.keras.callbacks.LambdaCallback(
                on_epoch_end=lambda epoch, logs: [
                    gpu_utilization_fold.append(get_gpu_utilization()),
                    cpu_utilization_fold.append(psutil.cpu_percent(interval=None))
                ]
            )
        ]
    )

    foldwise_gpu_cpu_utilization[fold_no] = {
        "gpu": gpu_utilization_fold,
        "cpu": cpu_utilization_fold
    }
    fold_no += 1

# Visualization
colors = ['b', 'g', 'r', 'c', 'm', 'y', 'k', 'orange', 'purple', 'brown']
plt.figure(figsize=(12, 6))

# Plot GPU utilization
plt.subplot(1, 2, 1)
for fold, utilizations in foldwise_gpu_cpu_utilization.items():
    epochs = range(1, len(utilizations["gpu"]) + 1)
    plt.plot(epochs, utilizations["gpu"], label=f'Fold {fold} GPU', color=colors[fold % len(colors)])

plt.title('GPU Utilization Across Folds')
plt.xlabel('Epoch')
plt.ylabel('Utilization (%)')
plt.legend()

# Plot CPU utilization
plt.subplot(1, 2, 2)
for fold, utilizations in foldwise_gpu_cpu_utilization.items():
    epochs = range(1, len(utilizations["cpu"]) + 1)
    plt.plot(epochs, utilizations["cpu"], label=f'Fold {fold} CPU', color=colors[fold % len(colors)])

plt.title('CPU Utilization Across Folds')
plt.xlabel('Epoch')
plt.ylabel('Utilization (%)')
plt.legend()

plt.tight_layout()
plt.show()







import numpy as np
import os
import shutil
import subprocess
import psutil
from sklearn.model_selection import KFold
import tensorflow as tf
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Input, Conv2D, BatchNormalization, MaxPooling2D, UpSampling2D, Dense, Concatenate, GlobalAveragePooling2D, Layer
from tensorflow.keras.utils import to_categorical, Sequence
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.preprocessing.image import load_img, img_to_array
import matplotlib.pyplot as plt

# Helper function to load image paths and labels
def load_image_paths_and_labels(data_dir):
    image_paths = []
    labels = []
    class_names = sorted(os.listdir(data_dir))
    for class_index, class_name in enumerate(class_names):
        class_dir = os.path.join(data_dir, class_name)
        if os.path.isdir(class_dir):
            for image_name in os.listdir(class_dir):
                image_paths.append(os.path.join(class_dir, image_name))
                labels.append(class_index)
    return np.array(image_paths), np.array(labels), class_names

# Function to get GPU utilization using nvidia-smi
def get_gpu_utilization():
    try:
        result = subprocess.check_output(['nvidia-smi', '--query-gpu=utilization.gpu', '--format=csv,noheader,nounits'])
        return float(result.decode('utf-8').strip())
    except Exception as e:
        print(f"Error fetching GPU utilization: {e}")
        return 0.0

# Custom generator for loading images
class CustomImageSequence(Sequence):
    def __init__(self, image_paths, labels, batch_size, target_size):
        self.image_paths = image_paths
        self.labels = labels
        self.batch_size = batch_size
        self.target_size = target_size

    def __len__(self):
        return int(np.ceil(len(self.image_paths) / self.batch_size))

    def __getitem__(self, idx):
        batch_paths = self.image_paths[idx * self.batch_size:(idx + 1) * self.batch_size]
        batch_labels = self.labels[idx * self.batch_size:(idx + 1) * self.batch_size]

        images = []
        for path in batch_paths:
            img = load_img(path, target_size=self.target_size)
            img = img_to_array(img) / 255.0  # Normalize images to [0, 1]
            images.append(img)

        return np.array(images), np.array(batch_labels)

# Define a subclassed Layer for fuzzification
class FuzzifyLayer(Layer):
    def __init__(self, a=0.2, b=0.5, c=0.8, **kwargs):
        super(FuzzifyLayer, self).__init__(**kwargs)
        self.a = a
        self.b = b
        self.c = c

    def call(self, inputs):
        return tf.maximum(
            0.0,
            tf.minimum((inputs - self.a) / (self.b - self.a), (self.c - inputs) / (self.c - self.b))
        )

# Input layer
input_layer = Input(shape=(224, 224, 3))

# Denoising Expert
denoising_x = Conv2D(16, (3, 3), activation='relu', padding='same')(input_layer)
denoising_x = BatchNormalization()(denoising_x)
denoising_x = MaxPooling2D((2, 2), padding='same')(denoising_x)

denoising_x = Conv2D(32, (3, 3), activation='relu', padding='same')(denoising_x)
denoising_x = BatchNormalization()(denoising_x)
denoising_x = MaxPooling2D((2, 2), padding='same')(denoising_x)

denoising_x = Conv2D(32, (3, 3), activation='relu', padding='same')(denoising_x)
denoising_x = UpSampling2D((2, 2))(denoising_x)

denoising_x = Conv2D(16, (3, 3), activation='relu', padding='same')(denoising_x)
denoising_x = UpSampling2D((2, 2))(denoising_x)

denoising_x = Conv2D(32, (3, 3), activation='relu', padding='same')(denoising_x)
denoised_features = GlobalAveragePooling2D()(denoising_x)

# Fuzzy Logic Expert
fuzzy_input = FuzzifyLayer()(input_layer)

fuzzy_x = Conv2D(32, (5, 5), activation='relu', padding='same')(fuzzy_input)
fuzzy_x = BatchNormalization()(fuzzy_x)
fuzzy_x = Conv2D(64, (5, 5), activation='relu', padding='same')(fuzzy_x)
fuzzy_x = MaxPooling2D((2, 2))(fuzzy_x)

fuzzy_x = Conv2D(128, (3, 3), activation='relu', padding='same')(fuzzy_x)
fuzzy_features = GlobalAveragePooling2D()(fuzzy_x)

# Adversarially Trained Expert
adversarial_x = Conv2D(64, (3, 3), activation='relu', padding='same')(input_layer)
adversarial_x = BatchNormalization()(adversarial_x)
adversarial_x = Conv2D(128, (3, 3), activation='relu', padding='same')(adversarial_x)
adversarial_x = MaxPooling2D((2, 2))(adversarial_x)

adversarial_x = Conv2D(256, (3, 3), activation='relu', padding='same')(adversarial_x)
adversarial_features = GlobalAveragePooling2D()(adversarial_x)

# Combine Features and Gating Network
combined_features = Concatenate()([fuzzy_features, adversarial_features, denoised_features])

gating_x = Dense(512, activation='relu')(combined_features)
final_output = Dense(3, activation='softmax')(gating_x)

# Build and Compile Model
model = Model(inputs=input_layer, outputs=final_output)
model.summary()
model.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])

# Load data
data_dir = '/content/drive/MyDrive/Colab Notebooks/BT/Training'
image_paths, labels, class_names = load_image_paths_and_labels(data_dir)
labels = to_categorical(labels, num_classes=len(class_names))

# K-Fold Cross-Validation
n_splits = 5
kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)

foldwise_gpu_cpu_utilization = {}
fold_no = 1

for train_index, val_index in kf.split(image_paths):
    print(f"Training for fold {fold_no} ...")
    train_paths, val_paths = image_paths[train_index], image_paths[val_index]
    train_labels, val_labels = labels[train_index], labels[val_index]

    train_gen = CustomImageSequence(train_paths, train_labels, batch_size=32, target_size=(224, 224))
    val_gen = CustomImageSequence(val_paths, val_labels, batch_size=32, target_size=(224, 224))

    gpu_utilization_fold = []
    cpu_utilization_fold = []

    history = model.fit(
        train_gen,
        epochs=50,
        validation_data=val_gen,
        verbose=1,
        callbacks=[
            tf.keras.callbacks.LambdaCallback(
                on_epoch_end=lambda epoch, logs: [
                    gpu_utilization_fold.append(get_gpu_utilization()),
                    cpu_utilization_fold.append(psutil.cpu_percent(interval=None))
                ]
            )
        ]
    )

    foldwise_gpu_cpu_utilization[fold_no] = {
        "gpu": gpu_utilization_fold,
        "cpu": cpu_utilization_fold
    }
    fold_no += 1



# Calculate and display average CPU and GPU utilization per fold
avg_utilization = {}

for fold, utilizations in foldwise_gpu_cpu_utilization.items():
    avg_gpu = np.mean(utilizations["gpu"])
    avg_cpu = np.mean(utilizations["cpu"])
    avg_utilization[fold] = {"avg_gpu": avg_gpu, "avg_cpu": avg_cpu}
    print(f"Fold {fold}: Average GPU Utilization = {avg_gpu:.2f}%, Average CPU Utilization = {avg_cpu:.2f}%")

# Visualization
colors = ['b', 'g', 'r', 'c', 'm', 'y', 'k', 'orange', 'purple', 'brown']
plt.figure(figsize=(12, 6))

# Plot GPU utilization
plt.subplot(1, 2, 1)
for fold, utilizations in foldwise_gpu_cpu_utilization.items():
    epochs = range(1, len(utilizations["gpu"]) + 1)
    plt.plot(epochs, utilizations["gpu"], label=f'Fold {fold} GPU', color=colors[fold % len(colors)])
    plt.axhline(y=avg_utilization[fold]["avg_gpu"], color=colors[fold % len(colors)], linestyle='--', label=f'Fold {fold} Avg GPU')

plt.title('GPU Utilization Across Folds')
plt.xlabel('Epoch')
plt.ylabel('Utilization (%)')
plt.legend()

# Plot CPU utilization
plt.subplot(1, 2, 2)
for fold, utilizations in foldwise_gpu_cpu_utilization.items():
    epochs = range(1, len(utilizations["cpu"]) + 1)
    plt.plot(epochs, utilizations["cpu"], label=f'Fold {fold} CPU', color=colors[fold % len(colors)])
    plt.axhline(y=avg_utilization[fold]["avg_cpu"], color=colors[fold % len(colors)], linestyle='--', label=f'Fold {fold} Avg CPU')

plt.title('CPU Utilization Across Folds')
plt.xlabel('Epoch')
plt.ylabel('Utilization (%)')
plt.legend()

plt.tight_layout()
plt.show()

# Gaps for Brain MRI (Cn5 vs Cn6 for each classifier)
brain_mri_gaps = {
    'C1': [0.04, 0.11, 0.11, 0.11],
    'C2': [0.32, 0.33, 0.32, 0.32],
    'C3': [1.08, 1.09, 1.08, 1.09],
    'C4': [0.21, 0.21, 0.21, 0.18],
    'C5': [3.61, 3.20, 3.61, 3.65]
}

# Gaps for Chest X-Ray (Cn5 vs Cn6 for each classifier)
chest_xray_gaps = {
    'C1': [1.09, 1.10, 1.09, 1.09],
    'C2': [0.79, 0.78, 0.79, 0.78],
    'C3': [7.13, 4.69, 7.13, 6.89],
    'C4': [0.35, 0.35, 0.35, 0.33],
    'C5': [0.35, 0.71, 0.35, 0.50]
}

# Function to calculate average gap for each dataset
def calculate_average_gap(gaps):
    average_gaps = {key: sum(values) / len(values) for key, values in gaps.items()}
    overall_average = sum(average_gaps.values()) / len(average_gaps)
    return average_gaps, overall_average

# Calculate average gaps for Brain MRI and Chest X-Ray
brain_mri_avg_gaps, brain_mri_overall_avg = calculate_average_gap(brain_mri_gaps)
chest_xray_avg_gaps, chest_xray_overall_avg = calculate_average_gap(chest_xray_gaps)

brain_mri_avg_gaps, brain_mri_overall_avg, chest_xray_avg_gaps, chest_xray_overall_avg