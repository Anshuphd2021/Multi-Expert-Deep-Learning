# -*- coding: utf-8 -*-
"""Ablation Study on the Impact of Individual Experts.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/19IqzTRBWwHeQ-a3U2u-jjJkbsCiQV-gC
"""

import tensorflow as tf
from tensorflow.keras.layers import Conv2D, BatchNormalization, MaxPooling2D, Dense, Flatten, Input
from tensorflow.keras.models import Model
import numpy as np
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.layers import Input, Conv2D, BatchNormalization, MaxPooling2D, Flatten, Dense, Lambda ,UpSampling2D

datagen = datagen = ImageDataGenerator(rescale=1./255)


training_set = datagen.flow_from_directory(
      '/content/drive/MyDrive/Colab Notebooks/BT/Training',
        target_size=(112,112),
        batch_size=32,
        shuffle= True,
        class_mode='categorical')

val_set = datagen.flow_from_directory(
        '/content/drive/MyDrive/Colab Notebooks/BT/Testing',
        target_size=(112,112),
        batch_size=16,
        shuffle= False,
        class_mode="categorical")

test_set = datagen.flow_from_directory(
        '/content/drive/MyDrive/Colab Notebooks/BT/Testing',
        target_size=(112,112),
        batch_size=32,
        shuffle= False,
        class_mode="categorical")



import numpy as np
import tensorflow as tf
from tensorflow.keras.layers import Input, Conv2D, BatchNormalization, MaxPooling2D, UpSampling2D, Flatten, Dense, Lambda, Concatenate, GlobalAveragePooling2D
from tensorflow.keras.models import Model

# Define Denoising Expert Model
def create_denoising_expert():
    input_layer = Input(shape=(112,112,3))  # Input noisy image

    # Encoding path (Feature Extraction)
    x = Conv2D(16, (3, 3), activation='relu', padding='same')(input_layer)
    x = BatchNormalization()(x)
    x = MaxPooling2D((2, 2), padding='same')(x)  # Down-sampling
    x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)
    x = BatchNormalization()(x)
    x = MaxPooling2D((2, 2), padding='same')(x)  # Down-sampling

    # Decoding path (Reconstruction)
    x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)
    x = UpSampling2D((2, 2))(x)  # Up-sampling
    x = Conv2D(16, (3, 3), activation='relu', padding='same')(x)
    x = UpSampling2D((2, 2))(x)  # Up-sampling

    # Output layer - Reconstructed (denoised) image
    x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)  # Keep spatial dimensions the same

    # Flatten the feature maps to pass to the gating network
    x = GlobalAveragePooling2D()(x)

    x = Dense(4, activation='softmax')(x)
    # Build model
    model = Model(inputs=input_layer, outputs=x)
    return model

# Define Fuzzy Logic Expert Model
def fuzzy_membership(x, a, b, c):
    return tf.maximum(0.0, tf.minimum((x - a) / (b - a), (c - x) / (c - b)))

def fuzzify_layer(input_layer):
    fuzzified = Lambda(lambda x: fuzzy_membership(x, 0.2, 0.5, 0.8))(input_layer)
    return fuzzified

def create_fuzzy_logic_expert():
    input_layer = Input(shape=(112,112,3))

    # Fuzzification of the input data
    fuzzified_input = fuzzify_layer(input_layer)

    # Regular CNN layers
    x = Conv2D(32, (5, 5), activation='relu', padding='same')(fuzzified_input)
    x = BatchNormalization()(x)
    x = Conv2D(64, (5, 5), activation='relu', padding='same')(x)
    x = MaxPooling2D((2, 2))(x)
    x = Conv2D(128, (3, 3), activation='relu', padding='same')(x)


    # Flatten and output layers
    x = GlobalAveragePooling2D()(x)
    x = Dense(4, activation='softmax')(x)

    # Build model
    model = Model(inputs=input_layer, outputs=x)
    return model

# Define Adversarially Trained Expert Model
def create_adversarially_trained_expert():
    input_layer = Input(shape=(112,112,3))
    x = Conv2D(64, (3, 3), activation='relu', padding='same')(input_layer)
    x = BatchNormalization()(x)
    x = Conv2D(128, (3, 3), activation='relu', padding='same')(x)
    x = MaxPooling2D((2, 2))(x)
    x = Conv2D(256, (3, 3), activation='relu', padding='same')(x)

    x = GlobalAveragePooling2D()(x)
    x = Dense(4, activation='softmax')(x)
    model = Model(inputs=input_layer, outputs=x)
    return model

# Define Gating Network Model
def create_gating_network(input_shape):
    input_layer = Input(shape=input_shape)
    x = Dense(512, activation='relu')(input_layer)
    x = Dense(4, activation='softmax')(x)
    model = Model(inputs=input_layer, outputs=x)
    return model

# Combine all models
def create_combined_model(input_shape):
    # Create each model
    denoising_expert = create_denoising_expert()
    fuzzy_logic_expert = create_fuzzy_logic_expert()
    adversarially_trained_expert = create_adversarially_trained_expert()

    # Define input layer
    input_layer = Input(shape=input_shape)

    # Get features from the denoising expert
    denoised_features = denoising_expert(input_layer)

    # Extract features from each expert
    fuzzy_features = fuzzy_logic_expert(input_layer)
    adversarial_features = adversarially_trained_expert(input_layer)

    # Concatenate features from all experts
    combined_features = Concatenate()([fuzzy_features, adversarial_features, denoised_features])

    # Define the gating network
    gating_network = create_gating_network(combined_features.shape[1:])

    # Final prediction
    final_output = gating_network(combined_features)

    # Create and compile the combined model
    model = Model(inputs=input_layer, outputs=final_output)
    return model

# Define input shape
input_shape = (112,112, 3)

# Create the combined model
model = create_combined_model(input_shape)

# Summary of the combined model
model.summary()

from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import EarlyStopping

# Training parameters
epochs = 50
batch_size = 32
learning_rate = 0.001

# Compile and train individual expert models
def train_and_evaluate(model, train_set, val_set, test_set, model_name):
    # Compile the model
    model.compile(optimizer=Adam(learning_rate=learning_rate),
                  loss='categorical_crossentropy',
                  metrics=['accuracy'])

    # Define early stopping
   # early_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)

    # Train the model
    print(f"Training {model_name}...")
    history = model.fit(
        train_set,
        validation_data=val_set,
        epochs=epochs
    )

    # Evaluate on the test set
    print(f"Evaluating {model_name}...")
    test_loss, test_accuracy = model.evaluate(test_set)
    print(f"{model_name} - Test Accuracy: {test_accuracy:.2f}")

    return test_loss, test_accuracy, history

# Train and evaluate the denoising expert
denoising_model = create_denoising_expert()
denoising_metrics = train_and_evaluate(denoising_model, training_set, val_set, test_set, "Denoising Expert")

# Train and evaluate the fuzzy logic expert
fuzzy_logic_model = create_fuzzy_logic_expert()
fuzzy_logic_metrics = train_and_evaluate(fuzzy_logic_model, training_set, val_set, test_set, "Fuzzy Logic Expert")

# Train and evaluate the adversarially trained expert
adversarial_model = create_adversarially_trained_expert()
adversarial_metrics = train_and_evaluate(adversarial_model, training_set, val_set, test_set, "Adversarial Expert")

# Train and evaluate the combined model
combined_model = create_combined_model((112, 112, 3))
combined_metrics = train_and_evaluate(combined_model, training_set, val_set, test_set, "Combined Model")

# Summarize results
print("\n--- Model Comparison ---")
print(f"Denoising Expert Test Accuracy: {denoising_metrics[1]:.2f}")
print(f"Fuzzy Logic Expert Test Accuracy: {fuzzy_logic_metrics[1]:.2f}")
print(f"Adversarial Expert Test Accuracy: {adversarial_metrics[1]:.2f}")